{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch scoring for large dataset, 01.03.2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Dataset, Workspace, Experiment\n",
    "import os\n",
    "azureml.core.VERSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My info\n",
    "ws = Workspace.from_config()\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, datastore.name, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"automl-compute\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                                min_nodes=compute_min_nodes,\n",
    "                                                                max_nodes=compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular dataset - registering at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "##########################\n",
    "#diabetes data\n",
    "##############\n",
    "diabetes_data = Dataset.Tabular.from_delimited_files(path=[(datastore, '/helen/data/diabetes_data.txt')],separator=' ')\n",
    "diabetes_data = diabetes_data.register(workspace=ws, \n",
    "                                 name='diabetes_data',\n",
    "                                 description='diabetes data',\n",
    "                                 create_new_version=True)\n",
    "\n",
    "\n",
    "##########################\n",
    "#diabetes labels\n",
    "##############\n",
    "diabetes_labels = Dataset.Tabular.from_delimited_files(path=[(datastore, '/helen/data/diabetes_labels.txt')],separator=' ')\n",
    "diabetes_labels = diabetes_labels.register(workspace=ws,\n",
    "                                 name='diabetes_labels',\n",
    "                                 description='diabetes labels',\n",
    "                                 create_new_version=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular dataset - accessing in script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing dataset which is already registered\n",
    "# get dataset by dataset name\n",
    "diabetes_data = Dataset.get_by_name(workspace=ws, name='diabetes_data')\n",
    "\n",
    "df = diabetes_data.to_pandas_dataframe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - accessing in script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all models called \"best_model\" and display their version numbers\n",
    "from azureml.core.model import Model\n",
    "models = Model.list(ws, name='helen_test')\n",
    "for m in models:\n",
    "    print(m.name, m.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading model into variable\n",
    "modelname='helen_test'\n",
    "model = Model(ws, modelname, version=60)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./helen/script/helen_score.py\n",
    "\n",
    "\n",
    "import io\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def init():\n",
    "    global iris_model\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Iris model serving\")\n",
    "    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n",
    "    args, unknown_args = parser.parse_known_args()\n",
    "    \n",
    "    model_path = Model.get_model_path(args.model_name)\n",
    "    \n",
    "    print (model_path)\n",
    "    print (args.model_name)\n",
    "        \n",
    "    iris_model = joblib.load(open(model_path, 'rb'))\n",
    "       \n",
    "    #with open(model_path, 'rb') as model_file:\n",
    "    #    iris_model = pickle.load(model_file)\n",
    "    print (iris_model)\n",
    "\n",
    "\n",
    "def run(input_data):\n",
    "    # make inference\n",
    "    \n",
    "    print ('type initial ', type (input_data))\n",
    "    \n",
    "    num_rows, num_cols = input_data.shape\n",
    "    print ('data initial',input_data)\n",
    "    print ('inp df', input_data.shape)\n",
    "    #pred = iris_model.predict(input_data).reshape((num_rows, 1))\n",
    "    #print ('out ', pred.shape)\n",
    "    \n",
    "    df_np=input_data.to_numpy()\n",
    "    num_rows, num_cols = df_np.shape\n",
    "    print ('inp np', df_np.shape)\n",
    "    pred = iris_model.predict(df_np).reshape((num_rows, 1))\n",
    "    print ('data out',pred)\n",
    "    print ('out ', pred.shape)\n",
    "  \n",
    "    # cleanup output\n",
    "    result_numpy = np.append (input_data, pred, 1)\n",
    "    # CORRECT TO LIST result=result_numpy.tolist()\n",
    "    # CORRECT TO NUMPY result=result_numpy\n",
    "    result=pd.DataFrame(data=result_numpy)\n",
    "    \n",
    "    print ('type final ', type (result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory in my local comuter\n",
    "script_folder = './helen/script'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "os.listdir(script_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "scripts_folder = \"./helen/script\"\n",
    "script_file = \"helen_score.py\"\n",
    "\n",
    "# peek at contents\n",
    "with open(os.path.join(scripts_folder, script_file)) as inference_file:\n",
    "    print(inference_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating - Dataset to be used to output pipeline steps i.e. scored dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "output_folder = PipelineData(name='inferences', datastore=datastore,output_path_on_compute=\"helen/results\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating - Parallel run step i.e. to score large dataset in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env to run script\n",
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import CondaDependencies\n",
    "\n",
    "predict_conda_deps = CondaDependencies.create(pip_packages=[ \"scikit-learn==0.20.3\" ])\n",
    "\n",
    "predict_env = Environment(name=\"predict_environment\")\n",
    "predict_env.python.conda_dependencies = predict_conda_deps\n",
    "predict_env.docker.enabled = True\n",
    "predict_env.spark.precache_packages = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.pipeline.steps import ParallelRunStep, ParallelRunConfig\n",
    "\n",
    "# In a real-world scenario, you'll want to shape your process per node and nodes to fit your problem domain.\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "                    source_directory=scripts_folder,\n",
    "                    entry_script=script_file,  # the user script to run against each input\n",
    "                    mini_batch_size='1GB',\n",
    "                    error_threshold=5,\n",
    "                    output_action='append_row',\n",
    "                    environment=predict_env,\n",
    "                    compute_target=compute_target, \n",
    "                    node_count=1,\n",
    "                    process_count_per_node=1,\n",
    "                    run_invocation_timeout=600,\n",
    "                    #logging_level='DEBUG'\n",
    "                    logging_level='INFO')\n",
    "parallel_run_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run_config.source_directory_data_store ('workspaceblobstore')\n",
    "#help (parallel_run_config)\n",
    "parallel_run_config.logging_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed_helen_step = ParallelRunStep(\n",
    "    name='example-diabetes',\n",
    "    inputs=[diabetes_data.as_named_input('diabetes_data')],\n",
    "    output=output_folder,\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    models=[model],\n",
    "    arguments=['--model_name', 'helen_test'],\n",
    "    #CORRECT allow_reuse=True\n",
    "    allow_reuse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pipeline \n",
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[distributed_helen_step])\n",
    "\n",
    "pipeline_run = Experiment(ws, 'simple_score_pipeline').submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will output a table with link to the run details in azure portal\n",
    "pipeline_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUI\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Console logs\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To see results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VIEW RESULTS\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"iris_results\", ignore_errors=True)\n",
    "\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data(\"inferences\")\n",
    "prediction_output.download(local_path=\"iris_results\")\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(\"iris_results\"):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "# cleanup output format\n",
    "df = pd.read_csv(result_file, delimiter=\" \", header=None)\n",
    "df.columns = ['age', 'gender', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6','pred']\n",
    "print(\"Prediction has \", df.shape[0], \" rows\")\n",
    "\n",
    "random_subset = df.sample(n=20)\n",
    "random_subset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: testing that run () works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring script\n",
    "import io\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def init():\n",
    "    global iris_model\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Iris model serving\")\n",
    "    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n",
    "    \n",
    "    model_path = Model.get_model_path(args.model_name)\n",
    "   \n",
    "    with open(model_path, 'rb') as model_file:\n",
    "        iris_model = pickle.load(model_file)\n",
    "\n",
    "\n",
    "def run(input_data):\n",
    "    # make inference\n",
    "    print ('inp ' , input_data.shape)\n",
    "    num_rows, num_cols = input_data.shape\n",
    "    print ('inp ' , input_data.shape)\n",
    "    pred = iris_model.predict(input_data).reshape((num_rows, 1))\n",
    "    print ('out ', pred.shape)\n",
    "    # cleanup output\n",
    "    #result = input_data.drop(input_data.columns[9:], axis=1)\n",
    "    result_numpy = np.append (input_data, pred, 1)\n",
    "    \n",
    "   \n",
    "    # CORRECT AS LIST -----result=result_numpy.tolist()\n",
    "    result=result_numpy\n",
    "\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading model for testing\n",
    "# SCORING \n",
    "# Registered model - downlaoding it, in order to use it for scoring\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model, Dataset\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "\n",
    "modelname='helen_test'\n",
    "model_file= \"diabetes_helen.pkl\"\n",
    "\n",
    "output_dir='./helen/download'\n",
    "os.makedirs (output_dir,exist_ok=True)\n",
    "\n",
    "model = Model(ws, modelname, version=4)\n",
    "model.download(target_dir=output_dir, exist_ok=True)\n",
    "print (model)\n",
    "\n",
    "\n",
    "model_file_name = os.path.join(output_dir, model_file)\n",
    "os.stat(model_file_name)\n",
    "iris_model = joblib.load(open(model_file_name, 'rb'))\n",
    "\n",
    "#Accessing dataset which is already registered\n",
    "# get dataset by dataset name\n",
    "diabetes_data = Dataset.get_by_name(workspace=ws, name='diabetes_data')\n",
    "\n",
    "df = diabetes_data.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing that my run scripts works\n",
    "df = diabetes_data.to_pandas_dataframe()\n",
    "df_np=df.to_numpy()\n",
    "print (df_np.shape)\n",
    "\n",
    "helen_numpy=run (df_np)\n",
    "print (type (helen_numpy))\n",
    "print (helen_numpy[1:5,:])\n",
    "\n",
    "helen_list=helen_numpy.tolist()\n",
    "print (type(helen_list))\n",
    "\n",
    "helen_pandas=pd.DataFrame(data=helen_numpy)\n",
    "print (type(helen_pandas))\n",
    "helen_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Another way to write scoring script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./helen/script/helen_score.py\n",
    "# Alternative: THIS DOES NOT WORK !!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "import io\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "def init():\n",
    "\n",
    "    global diabetes_model\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Diabetes model serving\")\n",
    "    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n",
    "    args, unknown_args = parser.parse_known_args()\n",
    "\n",
    "    model_path = Model.get_model_path(args.model_name)\n",
    "   \n",
    "    \n",
    "    with open(model_path, 'rb') as model_file:\n",
    "        diabetes_model = pickle.load(model_file)\n",
    "\n",
    "\n",
    "def run(input_data):\n",
    "    # make inference\n",
    "    num_rows, num_cols = input_data.shape\n",
    "    pred = diabetes_model.predict(input_data).reshape((num_rows, 1))\n",
    "\n",
    "    # cleanup output\n",
    "    #result = input_data.drop(input_data.columns[4:], axis=1)\n",
    "    #result = input_data.drop(input_data.columns[9:], axis=1)\n",
    "    #result['variety'] = pred\n",
    "    result=pred\n",
    "    \n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
