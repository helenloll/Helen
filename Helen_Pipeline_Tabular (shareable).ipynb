{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular dataset with pipleine - light version to share , 19.11.2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.85'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Datastore, Dataset, Workspace, Experiment, RunConfiguration\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.runconfig import CondaDependencies\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "import os\n",
    "azureml.core.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library configuration succeeded\n"
     ]
    }
   ],
   "source": [
    "#Write workspace to file\n",
    "from azureml.core import Workspace\n",
    "\n",
    "subscription_id = '8b2f4e94-e7b0-42e5-b775-dd2d5968c4e6'\n",
    "resource_group  = 'HelenMachineLearning'\n",
    "workspace_name  = 'HelenMachineLearning'\n",
    "\n",
    "try:\n",
    "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    ws.write_config()\n",
    "    print('Library configuration succeeded')\n",
    "except:\n",
    "    print('Workspace not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HelenMachineLearning\n",
      "HelenMachineLearning\n",
      "eastus2\n",
      "8b2f4e94-e7b0-42e5-b775-dd2d5968c4e6\n",
      "workspaceblobstore\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x1c0ff9a02e8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My info\n",
    "ws = Workspace.from_config()\n",
    "datastore = ws.get_default_datastore()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, datastore.name, sep = '\\n')\n",
    "\n",
    "helen_datastore = Datastore.get(workspace=ws, datastore_name='helen_blobstore')\n",
    "helen_datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. automl-compute\n"
     ]
    }
   ],
   "source": [
    "# Attache Azure ML Compute as Cluster of low cost nodes\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"automl-compute\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                                min_nodes=compute_min_nodes,\n",
    "                                                                max_nodes=compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datastore - registering at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING DATASTORE\n",
    "\n",
    "from azureml.core import Workspace, Experiment, Datastore, Dataset\n",
    "\n",
    "blob_datastore_name='helen_blobstore' # Name of the datastore to workspace\n",
    "container_name=os.getenv(\"BLOB_CONTAINER\", \"helenml\") # Name of Azure blob container\n",
    "account_name=os.getenv(\"BLOB_ACCOUNTNAME\", \"storagehelen\") # Storage account name\n",
    "account_key=os.getenv(\"BLOB_ACCOUNT_KEY\", \"jecd6i4x/skj0kPHWinl1N50ofZa44uAnJPOPVnPPFOQ3sLesacisIQYVOXolRpC0n6OwxblOV9H6G6MNSbOsg==\") # Storage account key\n",
    "\n",
    "helen_datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                         datastore_name=blob_datastore_name, \n",
    "                                                         container_name=container_name, \n",
    "                                                         account_name=account_name,\n",
    "                                                         account_key=account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml_globaldatasets AzureBlob mmstorageeastus2 globaldatasets\n",
      "helen_blobstore AzureBlob storagehelen helenml\n",
      "iris_model_datastore AzureBlob pipelinedata iris-model\n",
      "iris_datastore_data AzureBlob pipelinedata sampledata\n",
      "workspaceblobstore AzureBlob helenmachinele4347574357 azureml-blobstore-9c9fbf0e-97f5-41fb-a761-24769ea9187d\n",
      "workspacefilestore AzureFile helenmachinele4347574357 azureml-filestore-9c9fbf0e-97f5-41fb-a761-24769ea9187d\n"
     ]
    }
   ],
   "source": [
    "# List all datastores registered in the current workspace\n",
    "datastores = ws.datastores\n",
    "for name, datastore in datastores.items():\n",
    "    print (name, datastore.datastore_type, datastore.account_name, datastore.container_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular dataset - registering at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diabetes_data.txt', 'diabetes_labels.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_folder=\"./helen/data/\"\n",
    "os.listdir(script_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./helen/data/diabetes_data.txt\n",
      "Uploaded ./helen/data/diabetes_data.txt, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./helen/data/diabetes_labels.txt\n",
      "Uploaded ./helen/data/diabetes_labels.txt, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_ea0615884ba7476cbacb3b17bcc94c92"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uploading data files once\n",
    "helen_datastore = Datastore.get(workspace=ws, datastore_name='helen_blobstore')\n",
    "\n",
    "\n",
    "\n",
    "helen_datastore.upload_files(files = ['./helen/data/diabetes_data.txt'],\n",
    "                       target_path = '/helen/data',\n",
    "                       overwrite = True,\n",
    "                       show_progress = True)\n",
    "\n",
    "\n",
    "helen_datastore.upload_files(files = ['./helen/data/diabetes_labels.txt'],\n",
    "                       target_path = '/helen/data',\n",
    "                       overwrite = True,\n",
    "                       show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering Tabular data ONCE\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "helen_datastore = Datastore.get(workspace=ws, datastore_name='helen_blobstore')\n",
    "\n",
    "##########################\n",
    "#diabetes data\n",
    "##############\n",
    "diabetes_data = Dataset.Tabular.from_delimited_files(path=[(helen_datastore, '/helen/data/diabetes_data.txt')],separator=' ')\n",
    "diabetes_data = diabetes_data.register(workspace=ws, \n",
    "                                 name='diabetes_data',\n",
    "                                 description='diabetes data',\n",
    "                                 create_new_version=True)\n",
    "\n",
    "\n",
    "##########################\n",
    "#diabetes labels\n",
    "##############\n",
    "diabetes_labels = Dataset.Tabular.from_delimited_files(path=[(helen_datastore, '/helen/data/diabetes_labels.txt')],separator=' ')\n",
    "diabetes_labels = diabetes_labels.register(workspace=ws,\n",
    "                                 name='diabetes_labels',\n",
    "                                 description='diabetes labels',\n",
    "                                 create_new_version=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular data set - accessing it in scipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0380759064</th>\n",
       "      <th>0.0506801187</th>\n",
       "      <th>0.0616962065</th>\n",
       "      <th>0.0218723550</th>\n",
       "      <th>-0.0442234984</th>\n",
       "      <th>-0.0348207628</th>\n",
       "      <th>-0.0434008457</th>\n",
       "      <th>-0.0025922620</th>\n",
       "      <th>0.0199084209</th>\n",
       "      <th>-0.0176461252</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.092695</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.040696</td>\n",
       "      <td>-0.019442</td>\n",
       "      <td>-0.068991</td>\n",
       "      <td>-0.079288</td>\n",
       "      <td>0.041277</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.041180</td>\n",
       "      <td>-0.096346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.047163</td>\n",
       "      <td>-0.015999</td>\n",
       "      <td>-0.040096</td>\n",
       "      <td>-0.024800</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.062913</td>\n",
       "      <td>-0.038357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.063504</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.001895</td>\n",
       "      <td>0.066630</td>\n",
       "      <td>0.090620</td>\n",
       "      <td>0.108914</td>\n",
       "      <td>0.022869</td>\n",
       "      <td>0.017703</td>\n",
       "      <td>-0.035817</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.013953</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.014956</td>\n",
       "      <td>0.011349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.070900</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>-0.033214</td>\n",
       "      <td>-0.012577</td>\n",
       "      <td>-0.034508</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.067736</td>\n",
       "      <td>-0.013504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.096328</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.083808</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>-0.103389</td>\n",
       "      <td>-0.090561</td>\n",
       "      <td>-0.013948</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.062913</td>\n",
       "      <td>-0.034215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0380759064  0.0506801187  0.0616962065  0.0218723550  -0.0442234984  \\\n",
       "0     -0.001882     -0.044642     -0.051474     -0.026328      -0.008449   \n",
       "1      0.085299      0.050680      0.044451     -0.005671      -0.045599   \n",
       "2     -0.089063     -0.044642     -0.011595     -0.036656       0.012191   \n",
       "3      0.005383     -0.044642     -0.036385      0.021872       0.003935   \n",
       "4     -0.092695     -0.044642     -0.040696     -0.019442      -0.068991   \n",
       "5     -0.045472      0.050680     -0.047163     -0.015999      -0.040096   \n",
       "6      0.063504      0.050680     -0.001895      0.066630       0.090620   \n",
       "7      0.041708      0.050680      0.061696     -0.040099      -0.013953   \n",
       "8     -0.070900     -0.044642      0.039062     -0.033214      -0.012577   \n",
       "9     -0.096328     -0.044642     -0.083808      0.008101      -0.103389   \n",
       "\n",
       "   -0.0348207628  -0.0434008457  -0.0025922620  0.0199084209  -0.0176461252  \n",
       "0      -0.019163       0.074412      -0.039493     -0.068330      -0.092204  \n",
       "1      -0.034194      -0.032356      -0.002592      0.002864      -0.025930  \n",
       "2       0.024991      -0.036038       0.034309      0.022692      -0.009362  \n",
       "3       0.015596       0.008142      -0.002592     -0.031991      -0.046641  \n",
       "4      -0.079288       0.041277      -0.076395     -0.041180      -0.096346  \n",
       "5      -0.024800       0.000779      -0.039493     -0.062913      -0.038357  \n",
       "6       0.108914       0.022869       0.017703     -0.035817       0.003064  \n",
       "7       0.006202      -0.028674      -0.002592     -0.014956       0.011349  \n",
       "8      -0.034508      -0.024993      -0.002592      0.067736      -0.013504  \n",
       "9      -0.090561      -0.013948      -0.076395     -0.062913      -0.034215  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accessing dataset which is already registered\n",
    "# get dataset by dataset name\n",
    "diabetes_data = Dataset.get_by_name(workspace=ws, name='diabetes_data')\n",
    "\n",
    "df = diabetes_data.to_pandas_dataframe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>151.0000000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   151.0000000000\n",
       "0            75.0\n",
       "1           141.0\n",
       "2           206.0\n",
       "3           135.0\n",
       "4            97.0\n",
       "5           138.0\n",
       "6            63.0\n",
       "7           110.0\n",
       "8           310.0\n",
       "9           101.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accessing dataset which is already registered\n",
    "# get dataset by dataset name\n",
    "diabetes_labels = Dataset.get_by_name(workspace=ws, name='diabetes_labels')\n",
    "\n",
    "df = diabetes_labels.to_pandas_dataframe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['helen_prep_step1.py', 'helen_train1.py']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a directory in my local comuter\n",
    "script_folder = './helen/script'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "os.listdir(script_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./helen/script/diabetes_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./helen/script/diabetes_prep.py\n",
    "\n",
    "# simple read and train\n",
    "\n",
    "from azureml.core import Dataset, Run\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from matplotlib import pyplot as plot\n",
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "# AML content - start\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "print ('HELEN PREP STEP ')\n",
    "output_dir='./helen/output'\n",
    "os.makedirs ('./helen/output',exist_ok=True)\n",
    "run = Run.get_context()\n",
    "\n",
    "##########################################\n",
    "# get the input dataset by name\n",
    "##########################################\n",
    "\n",
    "dataset = run.input_datasets['diabetes_data']\n",
    "# load the TabularDataset to pandas DataFrame\n",
    "df = dataset.to_pandas_dataframe()\n",
    "x_array=df.to_numpy()\n",
    "\n",
    "\n",
    "dataset = run.input_datasets['diabetes_labels']\n",
    "# load the TabularDataset to pandas DataFrame\n",
    "df = dataset.to_pandas_dataframe()\n",
    "y_array=df.to_numpy()\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "\n",
    "run.log('data cnt',df.count())\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "# AML content - end\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "\n",
    "# My regural python code\n",
    "y=y_array\n",
    "X=x_array\n",
    "columns = ['age', 'gender', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "data = {\n",
    "   \"train\":{\"X\": X_train, \"y\": y_train},        \n",
    "   \"test\":{\"X\": X_test, \"y\": y_test}\n",
    "}\n",
    "reg = Ridge(alpha = 0.03)\n",
    "reg.fit(data['train']['X'], data['train']['y'])\n",
    "preds = reg.predict(data['test']['X'])\n",
    "print('Mean Squared Error is', mean_squared_error(preds, data['test']['y']))\n",
    "\n",
    "\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "# AML content - start\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "# Log mse in Azure ML logs\n",
    "run.log('mse', mean_squared_error(preds, data['test']['y']))\n",
    "\n",
    "# Save the model to the outputs directory for capture\n",
    "model_file = 'diabetes_helen.pkl'\n",
    "model_file_name=os.path.join(output_dir, model_file)\n",
    "joblib.dump(value = reg, filename = model_file_name);\n",
    "print(run.get_file_names())\n",
    "\n",
    "# upload the model file explicitly into artifacts Azure ML artifacts\n",
    "run.upload_file(name = model_file_name, path_or_stream = model_file_name)\n",
    "\n",
    "# register model in Azure ML Resitry \n",
    "model = run.register_model(model_name='helen_test',model_path=model_file_name)\n",
    "print(model.name, model.id, model.version, sep='\\t')\n",
    "\n",
    "for a in range (len(preds)):\n",
    "    run.log_row(\"Error: Estimate  - Actual\", x=a, y=abs (float (preds[a]) - float(y_test[a])))\n",
    "    \n",
    "\n",
    "# Creating file to oputput\n",
    "num_rows, num_cols = X_test.shape\n",
    "pred = preds.reshape((num_rows, 1))\n",
    "actual=y_test.reshape((num_rows, 1))\n",
    "\n",
    "tmp_npy = np.append (X_test, actual, 1)\n",
    "helen_numpy = np.append (tmp_npy, pred, 1)\n",
    "print ('helen_numpy shape ',helen_numpy.shape)\n",
    "\n",
    "helen_pandas=pd.DataFrame(data=helen_numpy)\n",
    "\n",
    "LOCALFILENAME='helen_score_file.txt'\n",
    "score_dir='./logs'\n",
    "score_dir='./helen/score'\n",
    "\n",
    "# Uploading file as articraft\n",
    "os.makedirs (score_dir,exist_ok=True)\n",
    "score_file = os.path.join(score_dir, LOCALFILENAME) \n",
    "helen_pandas.to_csv(score_file, sep=',', encoding='utf-8', index=False)\n",
    "print ('file name', score_file)\n",
    "\n",
    "# upload scored data explicitly into artifacts \n",
    "run.upload_file(name = score_file, path_or_stream = score_file)\n",
    "\n",
    "##########################################\n",
    "# create output refernce for dataset in pipeline step\n",
    "##########################################\n",
    "mounted_output_path = os.environ['AZUREML_DATAREFERENCE_diabetes_temp_ds']\n",
    "os.makedirs(mounted_output_path, exist_ok=True)\n",
    "score_file = os.path.join(mounted_output_path, LOCALFILENAME) \n",
    "helen_pandas.to_csv(score_file, sep=',', encoding='utf-8', index=False)\n",
    "print ('file name to somewhere', score_file)\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "# AML content - end\n",
    "##########################################\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./helen/script/diabetes_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./helen/script/diabetes_train.py\n",
    "\n",
    "\n",
    "# simple prep and train\n",
    "from azureml.core import Dataset, Run\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from matplotlib import pyplot as plot\n",
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "# AML content - start\n",
    "##########################################\n",
    "##########################################\n",
    "print ('HELEN TRAIN STEP ')\n",
    "\n",
    "output_dir='./helen/output'\n",
    "os.makedirs ('./helen/output',exist_ok=True)\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "#####################################\n",
    "# get the input dataset by name\n",
    "#####################################\n",
    "dataset = run.input_datasets['diabetes_data']\n",
    "# load the TabularDataset to pandas DataFrame\n",
    "df = dataset.to_pandas_dataframe()\n",
    "x_array=df.to_numpy()\n",
    "\n",
    "\n",
    "dataset = run.input_datasets['diabetes_labels']\n",
    "# load the TabularDataset to pandas DataFrame\n",
    "df = dataset.to_pandas_dataframe()\n",
    "y_array=df.to_numpy()\n",
    "\n",
    "\n",
    "dataset = run.input_datasets['diabetes_temp_ds']\n",
    "# load dataset into pandas dataframe\n",
    "df = dataset.to_pandas_dataframe()\n",
    "xy_array = df.to_numpy()\n",
    "#####################################\n",
    "# get the input dataset by name\n",
    "#####################################\n",
    "\n",
    "run.log('data cnt',df.count())\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "# AML content - end\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "\n",
    "\n",
    "# my regular python code\n",
    "y=y_array\n",
    "X=x_array\n",
    "columns = ['age', 'gender', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "data = {\n",
    "   \"train\":{\"X\": X_train, \"y\": y_train},        \n",
    "   \"test\":{\"X\": X_test, \"y\": y_test}\n",
    "}\n",
    "reg = Ridge(alpha = 0.03)\n",
    "reg.fit(data['train']['X'], data['train']['y'])\n",
    "preds = reg.predict(data['test']['X'])\n",
    "print('Mean Squared Error is', mean_squared_error(preds, data['test']['y']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "# AML content - start\n",
    "##########################################\n",
    "##########################################\n",
    "# Log mse to Azure ML\n",
    "run.log('mse', mean_squared_error(preds, data['test']['y']))\n",
    "\n",
    "# Save the model to the outputs directory for capture\n",
    "model_file = 'diabetes_helen.pkl'\n",
    "model_file_name=os.path.join(output_dir, model_file)\n",
    "joblib.dump(value = reg, filename = model_file_name);\n",
    "print(run.get_file_names())\n",
    "\n",
    "# upload the model file explicitly into artifacts in Azure ML\n",
    "run.upload_file(name = model_file_name, path_or_stream = model_file_name)\n",
    "\n",
    "# register model in Azure ML\n",
    "model = run.register_model(model_name='helen_test',model_path=model_file_name)\n",
    "print(model.name, model.id, model.version, sep='\\t')\n",
    "\n",
    "# Log in Azure ML\n",
    "for a in range (len(preds)):\n",
    "    run.log_row(\"Error: Estimate  - Actual\", x=a, y=abs (float (preds[a]) - float(y_test[a])))\n",
    "    \n",
    "# Logging histogram plot in Azue ML \n",
    "num_rows, num_cols = X_test.shape\n",
    "pred = preds.reshape((num_rows, 1))\n",
    "actual=y_test.reshape((num_rows, 1))\n",
    "tmp_npy = np.append (X_test, actual, 1)\n",
    "helen_numpy = np.append (tmp_npy, pred, 1)\n",
    "\n",
    "\n",
    "f=helen_numpy\n",
    "print (f.shape)\n",
    "fnrow=f.shape[0]\n",
    "fncol=f.shape[1]\n",
    "print ( \" rows \", fnrow, \"columns \", fncol)\n",
    "\n",
    "# Histograms to all columns\n",
    "i=0\n",
    "for i in range (fncol):\n",
    "    title= str (i) + ' nr column  '\n",
    "    plot.title(title)\n",
    "    plot.hist (f[:,[i]],bins=30,color='blue',edgecolor='white')\n",
    "    #CORRECTplot.show()\n",
    "    run.log_image ('Helen plot_' + str (i),plot=plot)\n",
    "    plot.clf()\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "# AML content - end\n",
    "##########################################\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating - Dataset to be used between pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define intermediate data\n",
    "helen_datastore = Datastore.get(workspace=ws, datastore_name='helen_blobstore')\n",
    "\n",
    "diabetes_temp_ds = PipelineData('diabetes_temp_ds', datastore=helen_datastore).as_dataset()\n",
    "\n",
    "# register output data as dataset\n",
    "diabetes_temp_ds= diabetes_temp_ds.register(name='diabetes_temp_ds', create_new_version=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating - Python step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# python script configuration\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create a new runconfig object\n",
    "aml_run_config = RunConfiguration()\n",
    "\n",
    "# Use the aml_compute you created above. \n",
    "aml_run_config.target = compute_target\n",
    "\n",
    "# Enable Docker\n",
    "aml_run_config.environment.docker.enabled = True\n",
    "\n",
    "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "aml_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Specify CondaDependencies obj, add necessary packages\n",
    "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['pandas','scikit-learn','matplotlib'], \n",
    "    pip_packages=['azureml-sdk', 'azureml-dataprep[fuse,pandas]'], \n",
    "    pin_sdk_version=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python step\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "\n",
    "helen_prep_step1 = PythonScriptStep(name='diabetes_prep',\n",
    "                             script_name=\"diabetes_prep.py\",\n",
    "                             inputs=[diabetes_data.as_named_input('diabetes_data'),diabetes_labels.as_named_input('diabetes_labels')],\n",
    "                             #CORRECT outputs=[diabetes_temp_ds.as_named_input('diabetes_temp_ds')],\n",
    "                             outputs=[diabetes_temp_ds],\n",
    "                             source_directory=script_folder,\n",
    "                             compute_target=compute_target,\n",
    "                             runconfig=aml_run_config,\n",
    "                             allow_reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating pipeline - with one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step diabetes_prep [5f37e9f6][39820733-6133-454a-bca0-ed9575eb99cd], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun b84a998f-39b3-4c9b-aa7a-8098106c8dca\n",
      "Link to Azure Machine Learning studio: https://ml.azure.com/experiments/helen_1steps_pipeline/runs/b84a998f-39b3-4c9b-aa7a-8098106c8dca?wsid=/subscriptions/8b2f4e94-e7b0-42e5-b775-dd2d5968c4e6/resourcegroups/HelenMachineLearning/workspaces/HelenMachineLearning\n",
      "PipelineRunId: b84a998f-39b3-4c9b-aa7a-8098106c8dca\n",
      "Link to Portal: https://ml.azure.com/experiments/helen_1steps_pipeline/runs/b84a998f-39b3-4c9b-aa7a-8098106c8dca?wsid=/subscriptions/8b2f4e94-e7b0-42e5-b775-dd2d5968c4e6/resourcegroups/HelenMachineLearning/workspaces/HelenMachineLearning\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 7f997a2b-4c80-4ba2-9e91-55af32d67d09\n",
      "Link to Portal: https://ml.azure.com/experiments/helen_1steps_pipeline/runs/7f997a2b-4c80-4ba2-9e91-55af32d67d09?wsid=/subscriptions/8b2f4e94-e7b0-42e5-b775-dd2d5968c4e6/resourcegroups/HelenMachineLearning/workspaces/HelenMachineLearning\n",
      "StepRun( diabetes_prep ) Status: NotStarted\n",
      "StepRun( diabetes_prep ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt\n",
      "========================================================================================================================\n",
      "2020-11-18T10:53:30Z Starting output-watcher...\n",
      "2020-11-18T10:53:30Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "84091f2c9e3a2df7b847fabb3760fe050ec10448384c4ea03a14b64773ffa4f7\n",
      "2020/11/18 10:54:07 setuptask.go:390: Starting App Insight Logger for task:  containerSetup\n",
      "2020/11/18 10:54:07 logger.go:297: Version: 3.0.01381.0008 Branch: .SourceBranch Commit: 9725c87\n",
      "2020/11/18 10:54:07 utils.go:309: /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/11/18 10:54:07 logger.go:297: sshd inside container not required for job, skipping setup.\n",
      "2020/11/18 10:54:07 appinsightlogger.go:40: All App Insights Logs was send successfully\n",
      "2020-11-18T10:54:16Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2020/11/18 10:53:25 setuptask.go:390: Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Version: 3.0.01381.0008 Branch: .SourceBranch Commit: 9725c87\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: runtime.GOOS linux\n",
      ">>>   2020/11/18 10:53:25 dynamicconfigs.go:70: Reading dyanamic configs\n",
      ">>>   2020/11/18 10:53:25 selfupdate.go:183: Container sas url: https://baiscriptseastus2prod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=jCOdu9JYnzJiH4sLkyP8uB30%2BkOIOkA489fe%2BjeZkEs%3D\n",
      ">>>   2020/11/18 10:53:25 utils.go:692: Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: no such file or directory\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: [in autoUpgradeFromJobNodeSetup] Is Azsecpack installed false, isEnable false,\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: azsecpack isEnable:false,turnoffaz:false\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: DetonationChamber is not enabled on this subscription: 8b2f4e94-e7b0-42e5-b775-dd2d5968c4e6\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: GPU count found: 0\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: AMLComputeXDSEndpoint:  https://eastus2-prodk8ds.batchai.core.windows.net\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Creating directory /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/config\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: This is not a aml-workstation (compute instance), current offer type: azureml. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Starting identity responder.\n",
      ">>>   2020/11/18 10:53:25 userlogger.go:47: Starting identity responder.\n",
      ">>>   2020/11/18 10:53:25 utils.go:321: Failed to open file /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/config/.batchai.IdentityResponder.envlist: open /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Logfile used for identity responder: /mnt/batch/tasks/workitems/127d09b5-e2b8-4732-ac83-ea7b52d1f5ef/job-1/7f997a2b-4c80-4ba2-9_524e0e99-9308-4b24-9112-53ef88cb24b9/IdentityResponderLog-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt\n",
      ">>>   2020/11/18 10:53:25 userlogger.go:47: Logfile used for identity responder: /mnt/batch/tasks/workitems/127d09b5-e2b8-4732-ac83-ea7b52d1f5ef/job-1/7f997a2b-4c80-4ba2-9_524e0e99-9308-4b24-9112-53ef88cb24b9/IdentityResponderLog-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Started Identity Responder for job.\n",
      ">>>   2020/11/18 10:53:25 userlogger.go:47: Started Identity Responder for job.\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Creating directory /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/wd\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Creating directory /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/shared\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Mounting job level file systems\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Creating directory /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts\n",
      ">>>   2020/11/18 10:53:25 protocol.go:795: Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/config/.amlcompute.datastorecredentials\n",
      ">>>   2020/11/18 10:53:25 protocol.go:797: Datastore credentials file not found, skipping.\n",
      ">>>   2020/11/18 10:53:25 protocol.go:764: Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/config/.master.runtimesastokens\n",
      ">>>   2020/11/18 10:53:25 protocol.go:766: Runtime sas tokens file not found, skipping.\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Start to pulling docker image: helenmachine59dbf329.azurecr.io/azureml/azureml_36cb0320ec4fbb9c97c19a3dbccf09ca\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Start pull docker image: helenmachine59dbf329.azurecr.io\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: No NFS configured\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Getting ACR Credentials from EMS\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: No Azure File Shares configured\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Requesting XDS for registry details.\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Attempt 1 of http call to https://eastus2-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/8b2f4e94-e7b0-42e5-b775-dd2d5968c4e6/resourceGroups/helenmachinelearning/workspaces/helenmachinelearning/clusters/automl-compute/nodes/tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d?api-version=2018-02-01\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Mounting blob file systems\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Blobfuse runtime version blobfuse 1.3.5\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Mounting azureml-blobstore-9c9fbf0e-97f5-41fb-a761-24769ea9187d container from helenmachinele4347574357 account at /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/11/18 10:53:25 logger.go:297: Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/11/18 10:53:25 userlogger.go:47: Running following command: &{/bin/bash [bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/configs/workspaceblobstore.cfg --log-level=LOG_WARNING] []  <nil>   [] <nil> <nil> <nil> <nil> <nil> false [] [] [] [] <nil> <nil>}\n",
      ">>>   2020/11/18 10:53:26 userlogger.go:47: Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore\n",
      ">>>   2020/11/18 10:53:26 logger.go:297: Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore\n",
      ">>>   2020/11/18 10:53:26 logger.go:297: Successfully mounted azureml-blobstore-9c9fbf0e-97f5-41fb-a761-24769ea9187d container from helenmachinele4347574357 account at /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore\n",
      ">>>   2020/11/18 10:53:26 logger.go:297: Mounting helenml container from storagehelen account at /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/helen_blobstore\n",
      ">>>   2020/11/18 10:53:26 logger.go:297: Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/11/18 10:53:26 logger.go:297: Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/11/18 10:53:26 userlogger.go:47: Running following command: &{/bin/bash [bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/helen_blobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/caches/helen_blobstore --file-cache-timeout-in-seconds=1000000 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/configs/helen_blobstore.cfg --log-level=LOG_WARNING] []  <nil>   [] <nil> <nil> <nil> <nil> <nil> false [] [] [] [] <nil> <nil>}\n",
      ">>>   2020/11/18 10:53:27 userlogger.go:47: Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/helen_blobstore\n",
      ">>>   2020/11/18 10:53:27 logger.go:297: Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/helen_blobstore\n",
      ">>>   2020/11/18 10:53:27 logger.go:297: Attempt 1. XDS Api returned non-successful ErrorCode: Success\n",
      ">>>    ErrorMessage: \n",
      ">>>   \n",
      ">>>   2020/11/18 10:53:27 logger.go:297: Got container registry details from credentials service for registry address: helenmachine59dbf329.azurecr.io.\n",
      ">>>   2020/11/18 10:53:27 logger.go:297: Writing ACR Details to file...\n",
      ">>>   2020/11/18 10:53:27 logger.go:297: Copying ACR Details file to worker nodes...\n",
      ">>>   2020/11/18 10:53:27 userlogger.go:47: Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2020/11/18 10:53:27 userlogger.go:47: Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2020/11/18 10:53:27 logger.go:297: Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2020/11/18 10:53:27 logger.go:297: Container registry is ACR.\n",
      ">>>   2020/11/18 10:53:27 logger.go:297: start login to the docker registry\n",
      ">>>   2020/11/18 10:53:27 logger.go:297: Successfully logged into the docker registry.\n",
      ">>>   2020/11/18 10:53:27 logger.go:297: Start run pull docker image command\n",
      ">>>   2020/11/18 10:53:27 logger.go:297: Successfully mounted helenml container from storagehelen account at /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/helen_blobstore\n",
      ">>>   2020/11/18 10:53:27 logger.go:297: No unmanaged file systems configured\n",
      ">>>   2020/11/18 10:53:27 logger.go:297: Creating directory /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml_compute_logs\n",
      ">>>   2020/11/18 10:53:29 logger.go:297: Creating directory /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/logs\n",
      ">>>   2020/11/18 10:53:30 logger.go:297: Creating directory /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/outputs\n",
      ">>>   2020/11/18 10:53:30 userlogger.go:47: Starting output-watcher...\n",
      ">>>   2020/11/18 10:53:49 logger.go:297: Pull docker image succeeded.\n",
      ">>>   2020/11/18 10:53:49 logger.go:297: Pull docker image time: 23.216360418s\n",
      ">>>   \n",
      ">>>   2020/11/18 10:53:49 logger.go:297: Docker Version that this nodes use are: 19.03.13+azure\n",
      ">>>   \n",
      ">>>   2020/11/18 10:53:49 utils.go:309: /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2020/11/18 10:53:49 logger.go:297: Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 7f997a2b-4c80-4ba2-9e91-55af32d67d09 -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/workitems/127d09b5-e2b8-4732-ac83-ea7b52d1f5ef/job-1/7f997a2b-4c80-4ba2-9_524e0e99-9308-4b24-9112-53ef88cb24b9/certs:/mnt/batch/tasks/workitems/127d09b5-e2b8-4732-ac83-ea7b52d1f5ef/job-1/7f997a2b-4c80-4ba2-9_524e0e99-9308-4b24-9112-53ef88cb24b9/certs -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml_compute_logs -v /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09:/mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09 -v /mnt/batch/tasks/workitems/127d09b5-e2b8-4732-ac83-ea7b52d1f5ef/job-1/7f997a2b-4c80-4ba2-9_524e0e99-9308-4b24-9112-53ef88cb24b9/wd:/mnt/batch/tasks/workitems/127d09b5-e2b8-4732-ac83-ea7b52d1f5ef/job-1/7f997a2b-4c80-4ba2-9_524e0e99-9308-4b24-9112-53ef88cb24b9/wd -v /opt/azureml:/opt/azureml:ro -w /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/config/.batchai.envlist --shm-size 2g -d -it --privileged --net=host helenmachine59dbf329.azurecr.io/azureml/azureml_36cb0320ec4fbb9c97c19a3dbccf09ca\n",
      ">>>   2020/11/18 10:54:08 logger.go:297: Container ssh is not required for job type.\n",
      ">>>   2020/11/18 10:54:08 logger.go:297: runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml_compute_logs\n",
      ">>>   2020/11/18 10:54:08 logger.go:297: runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_9b1bff161729480e04b53adf37938b29/bin/python /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"c881c39c-acac-4c26-b1f9-f3a102b1ffe0\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/11/18 10:54:08 logger.go:297: runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml_compute_logs/65_job_prep-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt\n",
      ">>>   2020/11/18 10:54:08 logger.go:297: runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml_compute_logs/65_job_prep-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt\n",
      ">>>   2020/11/18 10:54:08 logger.go:297: native cmd: cd /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09;/azureml-envs/azureml_9b1bff161729480e04b53adf37938b29/bin/python /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"c881c39c-acac-4c26-b1f9-f3a102b1ffe0\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/11/18 10:54:08 logger.go:297: runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2020/11/18 10:54:08 logger.go:297: runSpecialJobTask: Running cmd: &{/usr/bin/docker [docker exec -t 7f997a2b-4c80-4ba2-9e91-55af32d67d09 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;cd /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09;/azureml-envs/azureml_9b1bff161729480e04b53adf37938b29/bin/python /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"c881c39c-acac-4c26-b1f9-f3a102b1ffe0\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'] []  <nil> <nil> <nil> [] <nil> <nil> <nil> <nil> <nil> false [] [] [] [] <nil> <nil>}\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:09.240247] Entering job preparation.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:10.385911] Starting job preparation.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:10.385943] Extracting the control code.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:10.406354] fetching and extracting the control code on master node.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:10.406389] Starting extract_project.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:10.406438] Starting to extract zip file.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:11.357239] Finished extracting zip file.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:11.546604] Using urllib.request Python 3.0 or later\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:11.546704] Start fetching snapshots.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:11.546756] Start fetching snapshot.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:11.546776] Retrieving project from snapshot: c881c39c-acac-4c26-b1f9-f3a102b1ffe0\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 56\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:13.085208] Finished fetching snapshot.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:13.085245] Finished fetching snapshots.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:13.085259] Finished extract_project.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:13.107701] Finished fetching and extracting the control code.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:13.111671] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:13.112514] Start run_history_prep.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:13.207525] Entering context manager injector.\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: Acquired lockfile /tmp/7f997a2b-4c80-4ba2-9e91-55af32d67d09-datastore.lock to downloading input data references\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:15.398336] downloadDataStore completed\n",
      ">>>   2020/11/18 10:54:15 logger.go:297: runSpecialJobTask: preparation: [2020-11-18T10:54:15.404539] Job preparation is complete.\n",
      ">>>   2020/11/18 10:54:16 appinsightlogger.go:40: All App Insights Logs was send successfully\n",
      ">>>   2020/11/18 10:54:16 logger.go:297: Process Exiting with Code:  0\n",
      ">>>   \n",
      "2020-11-18T10:54:16Z 127.0.0.1 slots=4 max-slots=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2020/11/18 10:54:16 logger.go:297: Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2020/11/18 10:54:16 logger.go:297: Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "[2020-11-18T10:54:18.352580] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['diabetes_prep.py'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 124\n",
      "Entering Run History Context Manager.\n",
      "Current directory:  /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/workspaceblobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09\n",
      "Preparing to call script [ diabetes_prep.py ] with arguments: []\n",
      "After variable expansion, calling script [ diabetes_prep.py ] with arguments: []\n",
      "\n",
      "/azureml-envs/azureml_9b1bff161729480e04b53adf37938b29/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "HELEN PREP STEP \n",
      "Mean Squared Error is 2780.061072228511\n",
      "['azureml-logs/55_azureml-execution-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt', 'azureml-logs/65_job_prep-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/124_azureml.log', 'logs/azureml/executionlogs.txt', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/stderrlogs.txt', 'logs/azureml/stdoutlogs.txt']\n",
      "helen_test\thelen_test:77\t77\n",
      "helen_numpy shape  (89, 12)\n",
      "file name ./helen/score/helen_score_file.txt\n",
      "file name to somewhere /mnt/batch/tasks/shared/LS_root/jobs/helenmachinelearning/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/mounts/helen_blobstore/azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/diabetes_temp_ds/helen_score_file.txt\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 124\n",
      "\n",
      "\n",
      "[2020-11-18T10:54:46.539853] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "3 items cleaning up...\n",
      "Cleanup took 0.004189491271972656 seconds\n",
      "[2020-11-18T10:54:46.732247] Finished context manager injector.\n",
      "2020/11/18 10:54:48 logger.go:297: Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2020/11/18 10:54:48 logger.go:297: Process Exiting with Code:  0\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt\n",
      "===============================================================================================================\n",
      "[2020-11-18T10:54:48.845614] Entering job release\n",
      "[2020-11-18T10:54:50.428564] Starting job release\n",
      "[2020-11-18T10:54:50.434357] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 347\n",
      "[2020-11-18T10:54:50.436659] job release stage : upload_datastore starting...\n",
      "[2020-11-18T10:54:50.443203] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2020-11-18T10:54:50.443609] job release stage : execute_job_release starting...\n",
      "[2020-11-18T10:54:50.443873] job release stage : copy_batchai_cached_logs starting...\n",
      "[2020-11-18T10:54:50.444184] job release stage : copy_batchai_cached_logs completed...\n",
      "[2020-11-18T10:54:50.444623] Entering context manager injector.\n",
      "[2020-11-18T10:54:50.903126] job release stage : upload_datastore completed...\n",
      "[2020-11-18T10:54:51.402148] job release stage : send_run_telemetry starting...\n",
      "[2020-11-18T10:54:51.454844] job release stage : execute_job_release completed...\n",
      "[2020-11-18T10:54:52.975881] job release stage : send_run_telemetry completed...\n",
      "[2020-11-18T10:54:52.976169] Job release is complete\n",
      "\n",
      "StepRun(diabetes_prep) Execution Summary\n",
      "=========================================\n",
      "StepRun( diabetes_prep ) Status: Finished\n",
      "{'runId': '7f997a2b-4c80-4ba2-9e91-55af32d67d09', 'target': 'automl-compute', 'status': 'Completed', 'startTimeUtc': '2020-11-18T10:53:24.582386Z', 'endTimeUtc': '2020-11-18T10:55:01.642764Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'c881c39c-acac-4c26-b1f9-f3a102b1ffe0', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '39820733-6133-454a-bca0-ed9575eb99cd', 'azureml.nodeid': '5f37e9f6', 'azureml.pipelinerunid': 'b84a998f-39b3-4c9b-aa7a-8098106c8dca', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '2f57903a-6482-4398-9b9f-b1b3b3fdadc6'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_data', 'mechanism': 'Direct'}}, {'dataset': {'id': '5e873114-7ee5-47e3-b533-5216ae077529'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_labels', 'mechanism': 'Direct'}}], 'runDefinition': {'script': 'diabetes_prep.py', 'useAbsolutePath': False, 'arguments': [], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'automl-compute', 'dataReferences': {'diabetes_temp_ds': {'dataStoreName': 'helen_blobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/7f997a2b-4c80-4ba2-9e91-55af32d67d09/diabetes_temp_ds', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'diabetes_data': {'dataLocation': {'dataset': {'id': '2f57903a-6482-4398-9b9f-b1b3b3fdadc6', 'name': None, 'version': '4'}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'diabetes_data', 'pathOnCompute': None, 'overwrite': False}, 'diabetes_labels': {'dataLocation': {'dataset': {'id': '5e873114-7ee5-47e3-b533-5216ae077529', 'name': None, 'version': '4'}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'diabetes_labels', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'environment': {'name': 'Experiment helen_1steps_pipeline Environment', 'version': 'Autosave_2020-09-28T16:02:06Z_43ac6c0e', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk', 'azureml-dataprep[fuse,pandas]']}, 'pandas', 'scikit-learn', 'matplotlib'], 'name': 'azureml_9b1bff161729480e04b53adf37938b29'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': False}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml-logs/55_azureml-execution-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt?sv=2019-02-02&sr=b&sig=49w%2BWR09vxYh93DYGnTNxych7NBZ23NpctDtvh6JnRE%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r', 'azureml-logs/65_job_prep-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml-logs/65_job_prep-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt?sv=2019-02-02&sr=b&sig=BJoL75%2BuUtb4WPUmgnerHQAFBwA1FB8ZppFpuYN55Es%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=0fLjaBEDQB%2BWDE2Reh9%2BBBUcU60bV3n8IMUUx1VVCZI%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r', 'azureml-logs/75_job_post-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml-logs/75_job_post-tvmps_2d1328b5d096989c32492d484339c27353e4bc8f9781924cfe500e831b470156_d.txt?sv=2019-02-02&sr=b&sig=APhO93awEWwtKjSzug3fbqUqKuuAQQC2pkyQLgZ8EyY%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r', 'azureml-logs/process_info.json': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=qg0yJ%2FPfKgYXXIUvwfFl2tv3t%2BeIFn0YmctbaO2BwQU%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r', 'azureml-logs/process_status.json': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=QpT4JXjHI6A%2BR9a%2FfNLpU0q8ro9FEiuhsPe2g4PT6vM%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r', 'logs/azureml/124_azureml.log': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/logs/azureml/124_azureml.log?sv=2019-02-02&sr=b&sig=ThzOiN8nL2aFVfiZOORnLF4yPM3iLkb7dKj%2F%2BTqcXyo%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=CeBZ%2FYwvc26N2L4t6FcR8sXd1zUdLlzkGswPnc%2B13CI%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=XOtIv86ZyMidlsT%2FfM0VQv8HsnuWJ37aU1LW2%2FIywn0%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=mVjKMH%2BtMCF8IiZ8Tjm2yf1b%2BE8sMqgJojw68fNsHjM%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=s4cYR5rJgAWorzsrLzZpKfRQjWIPcqCqam5Pb%2BaoT8g%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.7f997a2b-4c80-4ba2-9e91-55af32d67d09/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=2emhWPtfPMXfLEFhjJcfI6Hf2LLu0gR1Bbwd%2FAUOhxU%3D&st=2020-11-18T10%3A44%3A57Z&se=2020-11-18T18%3A54%3A57Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'b84a998f-39b3-4c9b-aa7a-8098106c8dca', 'status': 'Completed', 'startTimeUtc': '2020-11-18T10:52:42.372702Z', 'endTimeUtc': '2020-11-18T10:55:09.219038Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.b84a998f-39b3-4c9b-aa7a-8098106c8dca/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=nkDPbVQOiBFYJ1GSIBMaA%2FSju76AjeNvblfPR4skaPc%3D&st=2020-11-18T10%3A45%3A13Z&se=2020-11-18T18%3A55%3A13Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.b84a998f-39b3-4c9b-aa7a-8098106c8dca/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=Bk726QWn6NO1zCdYWvFn%2BK2SfO09KEgCQr45KQcIlDc%3D&st=2020-11-18T10%3A45%3A13Z&se=2020-11-18T18%3A55%3A13Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.b84a998f-39b3-4c9b-aa7a-8098106c8dca/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=0W%2BLquwfTzSduRpQJkSkQJ2atzKAme0dErNmSv61M4o%3D&st=2020-11-18T10%3A45%3A13Z&se=2020-11-18T18%3A55%3A13Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run pipeline with one step\n",
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[helen_prep_step1])\n",
    "\n",
    "pipeline_run = Experiment(ws, 'helen_1steps_pipeline').submit(pipeline)\n",
    "\n",
    "# this will output a table with link to the run details in azure portal\n",
    "pipeline_run\n",
    "#Console logs\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating - estimator SKLearn step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION FOR TRAINING\n",
    "# Azure ML will create for me docker image \n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "data_dir='./helen/data'\n",
    "script_dir='./helen/script'\n",
    "\n",
    "est = SKLearn(source_directory=script_dir,\n",
    "                entry_script='diabetes_train.py',\n",
    "                pip_packages = ['azureml-sdk','azureml-dataprep[fuse,pandas]','matplotlib'],\n",
    "                compute_target=compute_target\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training step \n",
    "helen_train_step = EstimatorStep(name='diabates_train',\n",
    "                         estimator=est,\n",
    "                         estimator_entry_script_arguments=[],\n",
    "                         # parse prepared_fashion_ds into TabularDataset and use it as the input\n",
    "                         inputs=[diabetes_temp_ds.parse_delimited_files(), diabetes_data.as_named_input('diabetes_data'),diabetes_labels.as_named_input('diabetes_labels')],\n",
    "                         compute_target=compute_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating pipeline  - with two steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step diabetes_prep [ad0ce8d2][39820733-6133-454a-bca0-ed9575eb99cd], (This step is eligible to reuse a previous run's output)\n",
      "Created step diabates_train [7cfbe610][9ef22fb5-400a-48f3-8c53-a17fec70a3be], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun c2e190de-a989-4336-bd94-3a0fd6da4385\n",
      "Link to Azure Machine Learning studio: https://ml.azure.com/experiments/diabetes_pipeline/runs/c2e190de-a989-4336-bd94-3a0fd6da4385?wsid=/subscriptions/8b2f4e94-e7b0-42e5-b775-dd2d5968c4e6/resourcegroups/HelenMachineLearning/workspaces/HelenMachineLearning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>diabetes_pipeline</td><td>c2e190de-a989-4336-bd94-3a0fd6da4385</td><td>azureml.PipelineRun</td><td>Running</td><td><a href=\"https://ml.azure.com/experiments/diabetes_pipeline/runs/c2e190de-a989-4336-bd94-3a0fd6da4385?wsid=/subscriptions/8b2f4e94-e7b0-42e5-b775-dd2d5968c4e6/resourcegroups/HelenMachineLearning/workspaces/HelenMachineLearning\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: diabetes_pipeline,\n",
       "Id: c2e190de-a989-4336-bd94-3a0fd6da4385,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build pipeline & run experiment\n",
    "# run pipeline \n",
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[helen_prep_step1,helen_train_step])\n",
    "\n",
    "pipeline_run = Experiment(ws, 'diabetes_pipeline').submit(pipeline)\n",
    "\n",
    "# this will output a table with link to the run details in azure portal\n",
    "pipeline_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a51ce7ec37d4f35b0251485509febec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes_pipeline/runs/c2e190de-a989-4336-bd94-3a0fd6da4385?wsid=/subscriptions/8b2f4e94-e7b0-42e5-b775-dd2d5968c4e6/resourcegroups/HelenMachineLearning/workspaces/HelenMachineLearning\", \"run_id\": \"c2e190de-a989-4336-bd94-3a0fd6da4385\", \"run_properties\": {\"run_id\": \"c2e190de-a989-4336-bd94-3a0fd6da4385\", \"created_utc\": \"2020-11-18T11:12:58.354147Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2020-11-18T11:16:36.178581Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.c2e190de-a989-4336-bd94-3a0fd6da4385/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=rrh%2FushOL2ThdlDfEJxbjEVRn6AdrvDLcxWeZQPag1g%3D&st=2020-11-18T11%3A03%3A09Z&se=2020-11-18T19%3A13%3A09Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.c2e190de-a989-4336-bd94-3a0fd6da4385/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=QA%2F9TlG1Pjf2Ys1QznUDteC7WPAYKGHdlz13LE3kK24%3D&st=2020-11-18T11%3A03%3A09Z&se=2020-11-18T19%3A13%3A09Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.c2e190de-a989-4336-bd94-3a0fd6da4385/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=ONuen8SMHz6FlNOAJ%2Fh1gmLHiqnq%2F6WXeeF%2FxnHckO4%3D&st=2020-11-18T11%3A03%3A09Z&se=2020-11-18T19%3A13%3A09Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:03:37\"}, \"child_runs\": [{\"run_id\": \"83991d28-32ae-4f46-82b7-1e60ea8b97f6\", \"name\": \"diabetes_prep\", \"status\": \"Finished\", \"start_time\": \"2020-11-18T11:13:28.179755Z\", \"created_time\": \"2020-11-18T11:13:06.917404Z\", \"end_time\": \"2020-11-18T11:14:19.681764Z\", \"duration\": \"0:01:12\", \"run_number\": 11, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-18T11:13:06.917404Z\", \"is_reused\": \"\"}, {\"run_id\": \"13cc9ca0-2293-4bd9-8de4-afdeba48b568\", \"name\": \"diabates_train\", \"status\": \"Finished\", \"start_time\": \"2020-11-18T11:15:00.450944Z\", \"created_time\": \"2020-11-18T11:14:39.409797Z\", \"end_time\": \"2020-11-18T11:16:24.300154Z\", \"duration\": \"0:01:44\", \"run_number\": 12, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-18T11:14:39.409797Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-11-18 11:13:06Z] Submitting 1 runs, first five are: ad0ce8d2:83991d28-32ae-4f46-82b7-1e60ea8b97f6\\n[2020-11-18 11:14:38Z] Completing processing run id 83991d28-32ae-4f46-82b7-1e60ea8b97f6.\\n[2020-11-18 11:14:39Z] Submitting 1 runs, first five are: 7cfbe610:13cc9ca0-2293-4bd9-8de4-afdeba48b568\\n[2020-11-18 11:16:35Z] Completing processing run id 13cc9ca0-2293-4bd9-8de4-afdeba48b568.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"9b343538\": {\"node_id\": \"9b343538\", \"name\": \"diabetes_data\"}, \"9338a1d6\": {\"node_id\": \"9338a1d6\", \"name\": \"diabetes_labels\"}, \"418d7635\": {\"node_id\": \"418d7635\", \"name\": \"diabetes_data\"}, \"22998a8f\": {\"node_id\": \"22998a8f\", \"name\": \"diabetes_labels\"}}, \"module_nodes\": {\"ad0ce8d2\": {\"node_id\": \"ad0ce8d2\", \"name\": \"diabetes_prep\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"83991d28-32ae-4f46-82b7-1e60ea8b97f6\"}, \"7cfbe610\": {\"node_id\": \"7cfbe610\", \"name\": \"diabates_train\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"13cc9ca0-2293-4bd9-8de4-afdeba48b568\"}}, \"edges\": [{\"source_node_id\": \"9b343538\", \"source_node_name\": \"diabetes_data\", \"source_name\": \"data\", \"target_name\": \"diabetes_data\", \"dst_node_id\": \"ad0ce8d2\", \"dst_node_name\": \"diabetes_prep\"}, {\"source_node_id\": \"9338a1d6\", \"source_node_name\": \"diabetes_labels\", \"source_name\": \"data\", \"target_name\": \"diabetes_data\", \"dst_node_id\": \"ad0ce8d2\", \"dst_node_name\": \"diabetes_prep\"}, {\"source_node_id\": \"ad0ce8d2\", \"source_node_name\": \"diabetes_prep\", \"source_name\": \"diabetes_temp_ds\", \"target_name\": \"diabetes_temp_ds\", \"dst_node_id\": \"7cfbe610\", \"dst_node_name\": \"diabates_train\"}, {\"source_node_id\": \"418d7635\", \"source_node_name\": \"diabetes_data\", \"source_name\": \"data\", \"target_name\": \"diabetes_temp_ds\", \"dst_node_id\": \"7cfbe610\", \"dst_node_name\": \"diabates_train\"}, {\"source_node_id\": \"22998a8f\", \"source_node_name\": \"diabetes_labels\", \"source_name\": \"data\", \"target_name\": \"diabetes_temp_ds\", \"dst_node_id\": \"7cfbe610\", \"dst_node_name\": \"diabates_train\"}], \"child_runs\": [{\"run_id\": \"83991d28-32ae-4f46-82b7-1e60ea8b97f6\", \"name\": \"diabetes_prep\", \"status\": \"Finished\", \"start_time\": \"2020-11-18T11:13:28.179755Z\", \"created_time\": \"2020-11-18T11:13:06.917404Z\", \"end_time\": \"2020-11-18T11:14:19.681764Z\", \"duration\": \"0:01:12\", \"run_number\": 11, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-18T11:13:06.917404Z\", \"is_reused\": \"\"}, {\"run_id\": \"13cc9ca0-2293-4bd9-8de4-afdeba48b568\", \"name\": \"diabates_train\", \"status\": \"Finished\", \"start_time\": \"2020-11-18T11:15:00.450944Z\", \"created_time\": \"2020-11-18T11:14:39.409797Z\", \"end_time\": \"2020-11-18T11:16:24.300154Z\", \"duration\": \"0:01:44\", \"run_number\": 12, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-18T11:14:39.409797Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.85\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GUI\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: c2e190de-a989-4336-bd94-3a0fd6da4385\n",
      "Link to Portal: https://ml.azure.com/experiments/diabetes_pipeline/runs/c2e190de-a989-4336-bd94-3a0fd6da4385?wsid=/subscriptions/8b2f4e94-e7b0-42e5-b775-dd2d5968c4e6/resourcegroups/HelenMachineLearning/workspaces/HelenMachineLearning\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'c2e190de-a989-4336-bd94-3a0fd6da4385', 'status': 'Completed', 'startTimeUtc': '2020-11-18T11:13:01.512874Z', 'endTimeUtc': '2020-11-18T11:16:36.178581Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.c2e190de-a989-4336-bd94-3a0fd6da4385/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=rrh%2FushOL2ThdlDfEJxbjEVRn6AdrvDLcxWeZQPag1g%3D&st=2020-11-18T11%3A03%3A09Z&se=2020-11-18T19%3A13%3A09Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.c2e190de-a989-4336-bd94-3a0fd6da4385/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=QA%2F9TlG1Pjf2Ys1QznUDteC7WPAYKGHdlz13LE3kK24%3D&st=2020-11-18T11%3A03%3A09Z&se=2020-11-18T19%3A13%3A09Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://helenmachinele4347574357.blob.core.windows.net/azureml/ExperimentRun/dcid.c2e190de-a989-4336-bd94-3a0fd6da4385/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=ONuen8SMHz6FlNOAJ%2Fh1gmLHiqnq%2F6WXeeF%2FxnHckO4%3D&st=2020-11-18T11%3A03%3A09Z&se=2020-11-18T19%3A13%3A09Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Console logs\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
